{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-02-15T21:05:53.965581Z",
          "iopub.status.busy": "2023-02-15T21:05:53.964182Z",
          "iopub.status.idle": "2023-02-15T21:06:01.612704Z",
          "shell.execute_reply": "2023-02-15T21:06:01.611539Z",
          "shell.execute_reply.started": "2023-02-15T21:05:53.965511Z"
        },
        "trusted": true,
        "id": "IkoPamyQ5zNX",
        "outputId": "6256079c-5afa-403b-8b20-213046f44adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a27a9f031f7e>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplot_keras_history\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plot_keras_history'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import MaxPooling2D, concatenate, UpSampling2D\n",
        "from plot_keras_history import plot_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo_pzZpV5zNa"
      },
      "source": [
        "### Load data\n",
        "link: https://www.kaggle.com/datasets/hashbanger/ph2-resized\n",
        "\n",
        "- trainx: 200 imagens de lesões (192, 256, 3) rgb\n",
        "- trainy: 200 máscaras dessas imagens (192, 256, 1) grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:01.615870Z",
          "iopub.status.busy": "2023-02-15T21:06:01.615064Z",
          "iopub.status.idle": "2023-02-15T21:06:01.620900Z",
          "shell.execute_reply": "2023-02-15T21:06:01.619777Z",
          "shell.execute_reply.started": "2023-02-15T21:06:01.615827Z"
        },
        "trusted": true,
        "id": "vOnI6mIC5zNb"
      },
      "outputs": [],
      "source": [
        "# Importando as imagens e suas respectivas máscaras do meu Drive\n",
        "images_dir = Path(\"/content/drive/MyDrive/UFOP/PDI/archive/ph2_resized/trainx\")\n",
        "masks_dir = Path(\"/content/drive/MyDrive/UFOP/PDI/archive/ph2_resized/trainy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:01.623311Z",
          "iopub.status.busy": "2023-02-15T21:06:01.622542Z",
          "iopub.status.idle": "2023-02-15T21:06:01.746426Z",
          "shell.execute_reply": "2023-02-15T21:06:01.745349Z",
          "shell.execute_reply.started": "2023-02-15T21:06:01.623267Z"
        },
        "trusted": true,
        "id": "lG_bdW0k5zNc"
      },
      "outputs": [],
      "source": [
        "# Faz um sort dos arquivos pelo nome, para garantir a ordenação entre as listas de imagens e máscaras\n",
        "images = sorted(list(map(str, list(images_dir.glob(\"*.bmp\")))))\n",
        "masks = sorted(list(map(str, list(masks_dir.glob(\"*.bmp\")))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:01.752846Z",
          "iopub.status.busy": "2023-02-15T21:06:01.750568Z",
          "iopub.status.idle": "2023-02-15T21:06:03.495342Z",
          "shell.execute_reply": "2023-02-15T21:06:03.493941Z",
          "shell.execute_reply.started": "2023-02-15T21:06:01.752811Z"
        },
        "trusted": true,
        "id": "om7jjEFg5zNd"
      },
      "outputs": [],
      "source": [
        "# Coloca em NumPy\n",
        "X = np.array([np.array(Image.open(fname)) for fname in images])\n",
        "Y = np.array([np.array(Image.open(fname)) for fname in masks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:55:12.508867Z",
          "iopub.status.busy": "2023-02-15T20:55:12.508467Z",
          "iopub.status.idle": "2023-02-15T20:55:13.004268Z",
          "shell.execute_reply": "2023-02-15T20:55:12.997725Z",
          "shell.execute_reply.started": "2023-02-15T20:55:12.508835Z"
        },
        "trusted": true,
        "id": "Bc0G1Xy75zNd"
      },
      "outputs": [],
      "source": [
        "# Exibindo exemplos de lesão e sua respectivas máscaras-resposta\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(X[77])\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(Y[77], plt.cm.binary_r)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(X[30])\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(Y[30], plt.cm.binary_r)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO5iTFLy5zNf"
      },
      "source": [
        "### Preprocessing\n",
        "- dividir os dados entre treino e teste\n",
        "- aumentar os dados com rotation, horizontal flip, vertical flip (200 -> 5600\n",
        "\n",
        "- dividir os dados de treino entre treino e validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:07.638301Z",
          "iopub.status.busy": "2023-02-15T21:06:07.637022Z",
          "iopub.status.idle": "2023-02-15T21:06:07.663976Z",
          "shell.execute_reply": "2023-02-15T21:06:07.662890Z",
          "shell.execute_reply.started": "2023-02-15T21:06:07.638250Z"
        },
        "trusted": true,
        "id": "7KEyYIYc5zNh"
      },
      "outputs": [],
      "source": [
        "# Split em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:55:21.629000Z",
          "iopub.status.busy": "2023-02-15T20:55:21.628557Z",
          "iopub.status.idle": "2023-02-15T20:55:21.637563Z",
          "shell.execute_reply": "2023-02-15T20:55:21.635788Z",
          "shell.execute_reply.started": "2023-02-15T20:55:21.628952Z"
        },
        "trusted": true,
        "id": "uNHRRB8s5zNi"
      },
      "outputs": [],
      "source": [
        "print(len(x_train))\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:13.692403Z",
          "iopub.status.busy": "2023-02-15T21:06:13.691861Z",
          "iopub.status.idle": "2023-02-15T21:06:13.936971Z",
          "shell.execute_reply": "2023-02-15T21:06:13.935875Z",
          "shell.execute_reply.started": "2023-02-15T21:06:13.692361Z"
        },
        "trusted": true,
        "id": "pegcDnfL5zNk"
      },
      "outputs": [],
      "source": [
        "def random_rotation(x_image, y_image):\n",
        "    rows_x, cols_x, _ = x_image.shape\n",
        "    rows_y, cols_y = y_image.shape\n",
        "\n",
        "    random_angle = np.random.randint(-40,40)\n",
        "\n",
        "    # cv2.getRotationMatrix2D(center, angle, scale)\n",
        "    rotation_matrix_x = cv2.getRotationMatrix2D((cols_x/2, rows_x/2), random_angle, 1)\n",
        "    rotation_matrix_y = cv2.getRotationMatrix2D((cols_y/2, rows_y/2), random_angle, 1)\n",
        "\n",
        "    # warpAffine(inputImage, transformationMatrix, outputImageSize )\n",
        "    x_image = cv2.warpAffine(x_image, rotation_matrix_x, (cols_x,rows_x))\n",
        "    y_image = cv2.warpAffine(y_image.astype('float32'), rotation_matrix_y, (cols_y,rows_y))\n",
        "\n",
        "    return x_image, y_image.astype('int')\n",
        "\n",
        "\n",
        "def gen_flip(x_image, y_image, flag):\n",
        "    x_image = cv2.flip(x_image, flag)\n",
        "    y_image = cv2.flip(y_image.astype('float32'), flag)\n",
        "    return x_image, y_image.astype('int')\n",
        "\n",
        "def horizontal_flip(x_image, y_image):\n",
        "    return gen_flip(x_image, y_image, 1)\n",
        "\n",
        "def vertical_flip(x_image, y_image):\n",
        "    return gen_flip(x_image, y_image, 0)\n",
        "\n",
        "def img_augmentation(x, y, cycles):\n",
        "    x_temp = deepcopy(x)\n",
        "    y_temp = deepcopy(y)\n",
        "\n",
        "    x_rotated_images = []\n",
        "    y_rotated_images = []\n",
        "    x_flipped_horizontally_images = []\n",
        "    y_flipped_horizontally_images = []\n",
        "    x_flipped_vertically_images = []\n",
        "    y_flipped_vertically_images = []\n",
        "\n",
        "    for cycle in range(cycles):\n",
        "        for idx in range(len(x_temp)):\n",
        "            x,y = random_rotation(x_temp[idx], y_temp[idx])\n",
        "            x_rotated_images.append(x)\n",
        "            y_rotated_images.append(y)\n",
        "\n",
        "            x,y = horizontal_flip(x_temp[idx], y_temp[idx])\n",
        "            x_flipped_horizontally_images.append(x)\n",
        "            y_flipped_horizontally_images.append(y)\n",
        "\n",
        "            x,y = vertical_flip(x_temp[idx], y_temp[idx])\n",
        "            x_flipped_vertically_images.append(x)\n",
        "            y_flipped_vertically_images.append(y)\n",
        "\n",
        "        x_augmented_images = np.concatenate([x_rotated_images, x_flipped_horizontally_images, x_flipped_vertically_images])\n",
        "        y_augmented_images = np.concatenate([y_rotated_images, y_flipped_horizontally_images, y_flipped_vertically_images])\n",
        "\n",
        "    return x_augmented_images, y_augmented_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:17.310564Z",
          "iopub.status.busy": "2023-02-15T21:06:17.310158Z",
          "iopub.status.idle": "2023-02-15T21:06:25.849962Z",
          "shell.execute_reply": "2023-02-15T21:06:25.848841Z",
          "shell.execute_reply.started": "2023-02-15T21:06:17.310529Z"
        },
        "trusted": true,
        "id": "T2Lbv4Zg5zNl"
      },
      "outputs": [],
      "source": [
        "# aumentar os sets de treino e de teste\n",
        "x_train_augmented_images, y_train_augmented_images = img_augmentation(x_train, y_train, 3)\n",
        "\n",
        "x_train_full = np.concatenate([x_train, x_train_augmented_images])\n",
        "y_train_full = np.concatenate([y_train, y_train_augmented_images])\n",
        "\n",
        "x_test_augmented_images, y_test_augmented_images = img_augmentation(x_test, y_test, 3)\n",
        "\n",
        "x_test_full = np.concatenate([x_test, x_test_augmented_images])\n",
        "y_test_full = np.concatenate([y_test, y_test_augmented_images])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:55:41.150117Z",
          "iopub.status.busy": "2023-02-15T20:55:41.149690Z",
          "iopub.status.idle": "2023-02-15T20:55:41.157469Z",
          "shell.execute_reply": "2023-02-15T20:55:41.156314Z",
          "shell.execute_reply.started": "2023-02-15T20:55:41.150080Z"
        },
        "trusted": true,
        "id": "8Fv4Dumv5zNm"
      },
      "outputs": [],
      "source": [
        "print(len(x_train_full))\n",
        "print(len(x_test_full))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:30.765088Z",
          "iopub.status.busy": "2023-02-15T21:06:30.764674Z",
          "iopub.status.idle": "2023-02-15T21:06:31.477563Z",
          "shell.execute_reply": "2023-02-15T21:06:31.476417Z",
          "shell.execute_reply.started": "2023-02-15T21:06:30.765053Z"
        },
        "trusted": true,
        "id": "CDc93Ylk5zNn"
      },
      "outputs": [],
      "source": [
        "# dividindo treino entre treino e validação\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:55:45.857545Z",
          "iopub.status.busy": "2023-02-15T20:55:45.857133Z",
          "iopub.status.idle": "2023-02-15T20:55:45.865209Z",
          "shell.execute_reply": "2023-02-15T20:55:45.864099Z",
          "shell.execute_reply.started": "2023-02-15T20:55:45.857510Z"
        },
        "trusted": true,
        "id": "Fw7jb_sA5zNo"
      },
      "outputs": [],
      "source": [
        "print(len(x_train))\n",
        "print(len(x_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:35.900453Z",
          "iopub.status.busy": "2023-02-15T21:06:35.900030Z",
          "iopub.status.idle": "2023-02-15T21:06:35.914838Z",
          "shell.execute_reply": "2023-02-15T21:06:35.913263Z",
          "shell.execute_reply.started": "2023-02-15T21:06:35.900415Z"
        },
        "trusted": true,
        "id": "1U4JBe015zNp"
      },
      "outputs": [],
      "source": [
        "# Compara a sobreposição das áreas marcadas como verdadeiras nas máscaras y_true e y_pred.\n",
        "# A interseção dessas áreas é dividida pela união, Evitando divisão por zero\n",
        "# Quanto menor a distância de Jaccard, maior a similaridade entre as áreas segmentadas nas máscaras\n",
        "def jaccard_distance(y_true, y_pred, smooth=100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return (1 - jac)\n",
        "\n",
        "\n",
        "# Índice de Jaccard (IoU) entre duas máscaras binárias.\n",
        "# É uma métrica mais intuitiva, onde valores mais altos indicam melhor qualidade de segmentação\n",
        "def iou(y_true, y_pred, smooth = 100):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac\n",
        "\n",
        "\n",
        "# Valores mais altos (1) indicam uma melhor concordância entre as áreas segmentadas nas máscaras,\n",
        "# Também tem smooth\n",
        "def dice_coef(y_true, y_pred, smooth = 100):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "# Calcula a proporção de verdadeiros positivos (TP) em relação ao total de itens previstos como positivos pelo modelo\n",
        "# (TP + falsos positivos)\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# Calcula a proporção de verdadeiros positivos (TP) em relação ao total de itens que são realmente positivos\n",
        "# (TP + falsos negativos)\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return K.mean(K.equal(y_true, K.round(y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:39.093783Z",
          "iopub.status.busy": "2023-02-15T21:06:39.093134Z",
          "iopub.status.idle": "2023-02-15T21:06:39.108312Z",
          "shell.execute_reply": "2023-02-15T21:06:39.107136Z",
          "shell.execute_reply.started": "2023-02-15T21:06:39.093741Z"
        },
        "trusted": true,
        "id": "4qPKSkQ75zNr"
      },
      "outputs": [],
      "source": [
        "# MODELO SEGNET\n",
        "# ConvUnit: Uma unidade convolucional\n",
        "# ConvBlock: empilha várias unidades convolucionais em sequência, seguido por uma camada de MaxPooling\n",
        "# bloco de convolução e transposição que inclui uma camada de UpSampling + unidades convolucionais transpostas\n",
        "\n",
        "class ConvUnit(layers.Layer):\n",
        "    def __init__(self, filters, kernel_size, activation, transpose=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        if transpose:\n",
        "            self.conv = layers.Conv2DTranspose(filters, kernel_size, padding='same')\n",
        "        else:\n",
        "            self.conv = layers.Conv2D(filters, kernel_size, padding='same')\n",
        "\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.activation = layers.Activation(activation)\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class ConvBlock(layers.Layer):\n",
        "    def __init__(self, num_conv_unit, filters, kernel_size, activation, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_units = [ConvUnit(filters, kernel_size, activation) for _ in range(num_conv_unit)]\n",
        "        self.pool = layers.MaxPool2D()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for conv_unit in self.conv_units:\n",
        "            x = conv_unit(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class UpSamplingConvTBlock(layers.Layer):\n",
        "    def __init__(self, num_conv_unit, filters, kernel_size, activation, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.up_sampling = layers.UpSampling2D()\n",
        "        self.conv_units = [ConvUnit(filters, kernel_size, activation, transpose=True) for _ in range(num_conv_unit)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        x = self.up_sampling(x)\n",
        "        for conv_unit in self.conv_units:\n",
        "            x = conv_unit(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:06:41.642398Z",
          "iopub.status.busy": "2023-02-15T21:06:41.641766Z",
          "iopub.status.idle": "2023-02-15T21:06:41.657897Z",
          "shell.execute_reply": "2023-02-15T21:06:41.656556Z",
          "shell.execute_reply.started": "2023-02-15T21:06:41.642356Z"
        },
        "trusted": true,
        "id": "RLFvY2965zNs"
      },
      "outputs": [],
      "source": [
        "# O MODELO\n",
        "# ENCODER: Reduzir as dimensões espaciais da imagem e aumentar as representações de recursos\n",
        "# BOTTLENECK: (fully connected) com ativação ReLU para reduzir ainda mais a dimensionalidade das características\n",
        "# DECODER: aumentam as dimensões espaciais da imagem. recuperar detalhes e informações espaciais perdidas durante a codificação.\n",
        "def SegNet(activation=\"relu\"):\n",
        "    inputs = keras.Input(shape=(192, 256, 3))\n",
        "\n",
        "    # encoder\n",
        "    x = ConvBlock(num_conv_unit=2,\n",
        "                  filters=64,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=activation)(inputs)\n",
        "\n",
        "    x = ConvBlock(num_conv_unit=2,\n",
        "                  filters=128,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=activation)(x)\n",
        "\n",
        "    x = ConvBlock(num_conv_unit=3,\n",
        "                  filters=256,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=activation)(x)\n",
        "\n",
        "    x = ConvBlock(num_conv_unit=3,\n",
        "                  filters=512,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=activation)(x)\n",
        "\n",
        "    x = ConvBlock(num_conv_unit=3,\n",
        "                  filters=512,\n",
        "                  kernel_size=(3,3),\n",
        "                  activation=activation)(x)\n",
        "\n",
        "    # bottleneck\n",
        "    x = layers.Dense(1024, activation=activation)(x)\n",
        "    x = layers.Dense(1024, activation=activation)(x)\n",
        "\n",
        "    # decoder\n",
        "    x = UpSamplingConvTBlock(num_conv_unit=3,\n",
        "                             filters=512,\n",
        "                             kernel_size=(3,3),\n",
        "                             activation=activation)(x)\n",
        "\n",
        "    x = UpSamplingConvTBlock(num_conv_unit=2,\n",
        "                             filters=512,\n",
        "                             kernel_size=(3,3),\n",
        "                             activation=activation)(x)\n",
        "    x = ConvUnit(filters=256,\n",
        "                 kernel_size=(3,3),\n",
        "                 activation=activation,\n",
        "                 transpose=True)(x)\n",
        "\n",
        "    x = UpSamplingConvTBlock(num_conv_unit=2,\n",
        "                             filters=256,\n",
        "                             kernel_size=(3,3),\n",
        "                             activation=activation)(x)\n",
        "    x = ConvUnit(filters=128,\n",
        "                 kernel_size=(3,3),\n",
        "                 activation=activation,\n",
        "                 transpose=True)(x)\n",
        "\n",
        "    x = UpSamplingConvTBlock(num_conv_unit=1,\n",
        "                             filters=128,\n",
        "                             kernel_size=(3,3),\n",
        "                             activation=activation)(x)\n",
        "    x = ConvUnit(filters=64,\n",
        "                 kernel_size=(3,3),\n",
        "                 activation=activation,\n",
        "                 transpose=True)(x)\n",
        "\n",
        "    x = UpSamplingConvTBlock(num_conv_unit=1,\n",
        "                             filters=64,\n",
        "                             kernel_size=(3,3),\n",
        "                             activation=activation)(x)\n",
        "    x = ConvUnit(filters=1,\n",
        "                 kernel_size=(3,3),\n",
        "                 activation=\"sigmoid\")(x)\n",
        "\n",
        "    output = layers.Reshape((192, 256))(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:01:18.447908Z",
          "iopub.status.busy": "2023-02-15T20:01:18.447513Z",
          "iopub.status.idle": "2023-02-15T20:01:19.938860Z",
          "shell.execute_reply": "2023-02-15T20:01:19.937820Z",
          "shell.execute_reply.started": "2023-02-15T20:01:18.447873Z"
        },
        "trusted": true,
        "id": "KAPn29SW5zNt"
      },
      "outputs": [],
      "source": [
        "# treinar o modelo SegNet usando a estratégia de espelhamento do TensorFlow,\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with mirrored_strategy.scope():\n",
        "    segnet_model = SegNet(\"LeakyReLU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:01:50.309231Z",
          "iopub.status.busy": "2023-02-15T20:01:50.308825Z",
          "iopub.status.idle": "2023-02-15T20:01:50.333646Z",
          "shell.execute_reply": "2023-02-15T20:01:50.332659Z",
          "shell.execute_reply.started": "2023-02-15T20:01:50.309196Z"
        },
        "trusted": true,
        "id": "d8rAmxgV5zNt"
      },
      "outputs": [],
      "source": [
        "segnet_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "# compila e avalia diferentes aspectos do desempenho do modelo durante o processo de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:02:18.291746Z",
          "iopub.status.busy": "2023-02-15T20:02:18.290781Z",
          "iopub.status.idle": "2023-02-15T20:47:57.296286Z",
          "shell.execute_reply": "2023-02-15T20:47:57.295202Z",
          "shell.execute_reply.started": "2023-02-15T20:02:18.291704Z"
        },
        "trusted": true,
        "id": "G2JVKAF95zNu"
      },
      "outputs": [],
      "source": [
        "hist = segnet_model.fit(x_train, y_train, epochs=25, batch_size=8, validation_data= (x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T20:48:58.716578Z",
          "iopub.status.busy": "2023-02-15T20:48:58.716166Z",
          "iopub.status.idle": "2023-02-15T20:48:59.126873Z",
          "shell.execute_reply": "2023-02-15T20:48:59.125769Z",
          "shell.execute_reply.started": "2023-02-15T20:48:58.716544Z"
        },
        "trusted": true,
        "id": "pPJEf9km5zNu"
      },
      "outputs": [],
      "source": [
        "# salvar para comparar com a UNET\n",
        "segnet_model.save_weights(\"segnet_25.hdf5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsaxdArk5zNv"
      },
      "source": [
        "#### U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:07:00.378009Z",
          "iopub.status.busy": "2023-02-15T21:07:00.377579Z",
          "iopub.status.idle": "2023-02-15T21:07:00.387122Z",
          "shell.execute_reply": "2023-02-15T21:07:00.385749Z",
          "shell.execute_reply.started": "2023-02-15T21:07:00.377972Z"
        },
        "trusted": true,
        "id": "lFdfjp1s5zNv"
      },
      "outputs": [],
      "source": [
        "# unidade de Convolução Dupla\n",
        "class UDConvUnit(layers.Layer):\n",
        "    def __init__(self,filters, kernel_size, dropout = 0.40, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.conv = layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.activation = layers.Activation(\"LeakyReLU\")\n",
        "\n",
        "        self.conv2 = layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        self.activation2 = layers.Activation(\"LeakyReLU\")\n",
        "\n",
        "        self.dropout = layers.SpatialDropout2D(dropout)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.activation2(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:07:03.159867Z",
          "iopub.status.busy": "2023-02-15T21:07:03.159422Z",
          "iopub.status.idle": "2023-02-15T21:07:03.177842Z",
          "shell.execute_reply": "2023-02-15T21:07:03.176277Z",
          "shell.execute_reply.started": "2023-02-15T21:07:03.159827Z"
        },
        "trusted": true,
        "id": "5A1Yx__D5zNw"
      },
      "outputs": [],
      "source": [
        "#criando a rede Unet\n",
        "# várias (UDConvUnit + MaxPooling2D) para redução de resolução\n",
        "# UpSampling2D para aumentar a resolução dos recursos\n",
        "# A última camada usa uma convolução 1x1, representando a probabilidade de pertencer à classe de interesse.\n",
        "def UNet():\n",
        "    dropout_val = 0.40\n",
        "    inputs = keras.Input(shape=(192, 256, 3))\n",
        "\n",
        "    x1 = UDConvUnit(filters=32,\n",
        "                    kernel_size=(3,3))(inputs)\n",
        "    p1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
        "\n",
        "    x2 = UDConvUnit(filters=64,\n",
        "                    kernel_size=(3,3))(p1)\n",
        "    p2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
        "\n",
        "    x3 = UDConvUnit(filters=128,\n",
        "                    kernel_size=(3,3))(p2)\n",
        "    p3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
        "\n",
        "    x4 = UDConvUnit(filters=256,\n",
        "                    kernel_size=(3,3))(p3)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(x4)\n",
        "\n",
        "    x5 = UDConvUnit(filters=512,\n",
        "                    kernel_size=(3,3))(p4)\n",
        "    p5 = MaxPooling2D(pool_size=(2, 2))(x5)\n",
        "\n",
        "    x6 = UDConvUnit(filters=1024,\n",
        "                    kernel_size=(3,3))(p5)\n",
        "\n",
        "    u1 = concatenate([UpSampling2D(size=(2, 2))(x6), x5],\n",
        "                    axis=3)\n",
        "    ux1 = UDConvUnit(filters=512,\n",
        "                    kernel_size=(3,3))(u1)\n",
        "\n",
        "    u2 = concatenate([UpSampling2D(size=(2, 2))(ux1), x4],\n",
        "                    axis=3)\n",
        "    ux2 = UDConvUnit(filters=256,\n",
        "                    kernel_size=(3,3))(u2)\n",
        "\n",
        "    u3 = concatenate([UpSampling2D(size=(2, 2))(ux2), x3],\n",
        "                    axis=3)\n",
        "    ux3 = UDConvUnit(filters=128,\n",
        "                    kernel_size=(3,3))(u3)\n",
        "\n",
        "    u4 = concatenate([UpSampling2D(size=(2, 2))(ux3), x2],\n",
        "                    axis=3)\n",
        "    ux4 = UDConvUnit(filters=64,\n",
        "                    kernel_size=(3,3))(u4)\n",
        "\n",
        "    u5 = concatenate([UpSampling2D(size=(2, 2))(ux4), x1],\n",
        "                    axis=3)\n",
        "    ux5 = UDConvUnit(filters=32,\n",
        "                    kernel_size=(3,3),\n",
        "                    dropout = dropout_val)(u5)\n",
        "\n",
        "    x_final =  ConvUnit(filters=1,\n",
        "                       kernel_size=(1,1),\n",
        "                       activation=\"sigmoid\")(ux5)\n",
        "\n",
        "    output = layers.Reshape((192, 256))(x_final)\n",
        "\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T19:18:46.454990Z",
          "iopub.status.busy": "2023-02-15T19:18:46.454528Z",
          "iopub.status.idle": "2023-02-15T19:18:47.926919Z",
          "shell.execute_reply": "2023-02-15T19:18:47.926095Z",
          "shell.execute_reply.started": "2023-02-15T19:18:46.454947Z"
        },
        "trusted": true,
        "id": "8Co4Uc_w5zNy"
      },
      "outputs": [],
      "source": [
        "# treinar o modelo SegNet usando a estratégia de espelhamento do TensorFlow,\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with mirrored_strategy.scope():\n",
        "    unet_model = UNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T19:19:14.337451Z",
          "iopub.status.busy": "2023-02-15T19:19:14.337058Z",
          "iopub.status.idle": "2023-02-15T19:19:14.364998Z",
          "shell.execute_reply": "2023-02-15T19:19:14.363900Z",
          "shell.execute_reply.started": "2023-02-15T19:19:14.337418Z"
        },
        "trusted": true,
        "id": "XrXN9Lxf5zNz"
      },
      "outputs": [],
      "source": [
        "# # compila e avalia diferentes aspectos do desempenho do modelo durante o processo de treinamento e validação.\n",
        "unet_model.compile(optimizer=keras.optimizers.Adam(0.003), loss= [jaccard_distance],metrics=[iou, dice_coef, precision, recall, accuracy] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:08:38.018733Z",
          "iopub.status.busy": "2023-02-15T21:08:38.017369Z",
          "iopub.status.idle": "2023-02-15T21:08:38.835480Z",
          "shell.execute_reply": "2023-02-15T21:08:38.833556Z",
          "shell.execute_reply.started": "2023-02-15T21:08:38.018677Z"
        },
        "trusted": true,
        "id": "bLLqVioI5zNz"
      },
      "outputs": [],
      "source": [
        "# adaptando os formatos para float para aplicar as funções\n",
        "y_train = y_train.astype(float)\n",
        "y_test_full = y_test_full.astype(float)\n",
        "y_val = y_val.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T19:19:28.056172Z",
          "iopub.status.busy": "2023-02-15T19:19:28.055761Z",
          "iopub.status.idle": "2023-02-15T19:51:50.422977Z",
          "shell.execute_reply": "2023-02-15T19:51:50.421881Z",
          "shell.execute_reply.started": "2023-02-15T19:19:28.056136Z"
        },
        "trusted": true,
        "id": "9TC42L5c5zNz"
      },
      "outputs": [],
      "source": [
        "hist = unet_model.fit(x_train, y_train, epochs=25, batch_size=8, validation_data= (x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T19:52:31.415406Z",
          "iopub.status.busy": "2023-02-15T19:52:31.414790Z",
          "iopub.status.idle": "2023-02-15T19:52:31.805060Z",
          "shell.execute_reply": "2023-02-15T19:52:31.803932Z",
          "shell.execute_reply.started": "2023-02-15T19:52:31.415358Z"
        },
        "trusted": true,
        "id": "nzDuftly5zN0"
      },
      "outputs": [],
      "source": [
        "unet_model.save_weights(\"unet_model_25.hdf5\")\n",
        "# salvar para comparar mais tarde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P1GWiT05zN1"
      },
      "source": [
        "### compare models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:09:29.217163Z",
          "iopub.status.busy": "2023-02-15T21:09:29.216706Z",
          "iopub.status.idle": "2023-02-15T21:09:35.834737Z",
          "shell.execute_reply": "2023-02-15T21:09:35.833565Z",
          "shell.execute_reply.started": "2023-02-15T21:09:29.217124Z"
        },
        "trusted": true,
        "id": "pM9-uN4V5zN2"
      },
      "outputs": [],
      "source": [
        "# recuperar os weights\n",
        "segnet_model = SegNet(\"LeakyReLU\")\n",
        "segnet_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[iou, dice_coef, precision, recall, accuracy])\n",
        "segnet_model.load_weights(\"segnet_25.hdf5\")\n",
        "\n",
        "unet_model = UNet()\n",
        "unet_model.compile(optimizer=keras.optimizers.Adam(0.003), loss= [jaccard_distance],metrics=[iou, dice_coef, precision, recall, accuracy] )\n",
        "unet_model.load_weights(\"unet_model_25.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:31:18.247584Z",
          "iopub.status.busy": "2023-02-15T21:31:18.247063Z",
          "iopub.status.idle": "2023-02-15T21:31:19.176100Z",
          "shell.execute_reply": "2023-02-15T21:31:19.174915Z",
          "shell.execute_reply.started": "2023-02-15T21:31:18.247540Z"
        },
        "trusted": true,
        "id": "1Fqh007H5zN3"
      },
      "outputs": [],
      "source": [
        "img_num = 108\n",
        "img_pred1 = unet_model.predict(x_test_full[img_num].reshape(1,192,256,3))\n",
        "img_pred2 = segnet_model.predict(x_test_full[img_num].reshape(1,192,256,3))\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(x_test_full[img_num])\n",
        "plt.title('Imagem Original')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(y_test_full[img_num], plt.cm.binary_r)\n",
        "plt.title('Máscara Real')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(img_pred1.reshape(192, 256), plt.cm.binary_r)\n",
        "plt.title('Unet')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(img_pred2.reshape(192, 256), plt.cm.binary_r)\n",
        "plt.title('SegNet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-15T21:32:03.655637Z",
          "iopub.status.busy": "2023-02-15T21:32:03.655015Z",
          "iopub.status.idle": "2023-02-15T21:32:04.564660Z",
          "shell.execute_reply": "2023-02-15T21:32:04.561002Z",
          "shell.execute_reply.started": "2023-02-15T21:32:03.655598Z"
        },
        "trusted": true,
        "id": "6CKuRMkW5zN4"
      },
      "outputs": [],
      "source": [
        "img_num = 205\n",
        "img_pred1 = unet_model.predict(x_test_full[img_num].reshape(1,192,256,3))\n",
        "img_pred2 = segnet_model.predict(x_test_full[img_num].reshape(1,192,256,3))\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(x_test_full[img_num])\n",
        "plt.title('Imagem Original')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(y_test_full[img_num], plt.cm.binary_r)\n",
        "plt.title('Máscara Real')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(img_pred1.reshape(192, 256), plt.cm.binary_r)\n",
        "plt.title('Unet')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(img_pred2.reshape(192, 256), plt.cm.binary_r)\n",
        "plt.title('SegNet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0sQntPY5zN5"
      },
      "source": [
        "\n",
        "- U-Net: melhor nas bordas\n",
        "- SegNet: menos tuidos"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}